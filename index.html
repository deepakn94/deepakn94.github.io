<html>
  <head>
    <title>Deepak Narayanan</title>
    <link rel="stylesheet" type="text/css" href="stylesheets/index.css">
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-57602745-1', 'auto');
      ga('send', 'pageview');

    </script>
  </head>

  <body>

    <div id='nav'>
      <div class='name'>Deepak Narayanan</div>
      <a href='#about'>about me</a>
      <a href='#publications'>publications</a>
      <a href="#teaching">teaching</a>
      <a href='#contact'>contact</a>
    </div>

    <br>
    <br>
    <br>
    <br>
    <br>
    <br>

    <div id='about'>
      <div class='heading'>About me</div>
      <div class='content'>
        <img width="240" height="240" src='assets/headshots/deepak.JPG' align="right" style="margin-left:30px;">
        I am a final-year Ph.D. student in the Department of Computer Science at Stanford University, advised by <a href="https://cs.stanford.edu/~matei/"><b>Prof. Matei Zaharia</b></a>. I also work closely with <a href="https://www.microsoft.com/en-us/research/people/amar/"><b>Amar Phanishayee</b></a>.
        I am affiliated with <a href="https://dawn.cs.stanford.edu/"><b>Stanford DAWN</b></a> and supported by a <a href="https://www.nsfgrfp.org/"><b>National Science Foundation Graduate Research Fellowship</b></a>.
        <br>
        <br>
        My broad research interests include distributed systems and cloud computing -- in particular, I am interested in the Systems problems associated with learning and deploying machine learning
        models at scale.
        <br>
        <br>
        I graduated from MIT in 2015 with a SB in Computer Science and Mathematics and a MEng in EECS.
        <br>
        <br>
        My <a href="https://scholar.google.com/citations?user=sTzb6LAAAAAJ&hl=en"><b>Google scholar profile</b></a> has a relatively up-to-date list of publications.
      </div>
    </div>

    <div id='publications'>
      <div class='heading'>Publications</div>
      <div class='content'>
        <a href="assets/papers/megatron-sc21.pdf"><b>Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM</b></a><br />
        <b>Deepak Narayanan</b>, Mohammad Shoeybi, Jared Casper, Patrick LeGresley, Mostofa Patwary, Vijay Korthikanti, Dmitri Vainbrand, Prethvi Kashinkunti, Julie Bernauer, Bryan Catanzaro, Amar Phanishayee, Matei Zaharia. <br /><i>SuperComputing 2021 (to appear).</i>
        <br>
        <br>
        <a href=""><b>Solving Large-Scale Granular Resource Allocation Problems Efficiently with POP</b></a><br />
        <b>Deepak Narayanan</b>, Fiodar Kazhamiaka, Firas Abuzaid, Peter Kraft, Akshay Agrawal, Srikanth Kandula, Stephen Boyd, Matei Zaharia. <br /><i>SOSP 2021 (to appear).</i>
        <br>
        <br>
        <a href="assets/papers/pipedream_2bw-icml21.pdf"><b>Memory-Efficient Pipeline-Parallel DNN Training</b></a><br />
        <b>Deepak Narayanan</b>, Amar Phanishayee, Kaiyu Shi, Xie Chen, Matei Zaharia. <br /><i>ICML 2021.</i>
        <br>
        <br>
        <a href="assets/papers/gavel-osdi20.pdf"><b>Heterogeneity-Aware Cluster Scheduling Policies for Deep Learning Workloads</b></a><br />
        <b>Deepak Narayanan</b>, Keshav Santhanam, Fiodar Kazhamiaka, Amar Phanishayee, Matei Zaharia. <br /><i>OSDI 2020.</i>
        <br>
        <br>
        <a href="assets/papers/trainingonadime-dispa20.pdf"><b>Analysis and Exploitation of Dynamic Pricing in the Public Cloud for ML Training</b></a><br />
        <b>Deepak Narayanan</b>, Keshav Santhanam, Fiodar Kazhamiaka, Amar Phanishayee, Matei Zaharia. <br /><i>DISPA 2020.</i>
        <br>
        <br> 
        <a href="assets/papers/offloadannotations-atc20.pdf"><b>Offload Annotations: Bringing Heterogeneous Computing to Existing Libraries and Workloads</b></a><br />
        Gina Yuan, Shoumik Palkar, <b>Deepak Narayanan</b>, Matei Zaharia. <br /><i>USENIX ATC 2020.</i>
        <br>
        <br>
        <a href="assets/papers/willump-mlsys20.pdf"><b>Willump: A Statistically-Aware End-to-end Optimizer for Machine Learning Inference</b></a><br />
        Peter Kraft, Daniel Kang, <b>Deepak Narayanan</b>, Shoumik Palkar, Peter Bailis, Matei Zaharia. <br /><i>MLSys 2020.</i>
        <br>
        <br>
        <a href="assets/papers/mlperf-mlsys20.pdf"><b>MLPerf Training Benchmark</b></a><br />
        Peter Mattson, Christine Cheng, Cody Coleman, Greg Diamos, Paulius Micikevicius, David Patterson, Hanlin Tang, Gu-Yeon Wei, Peter Bailis, Victor Bittorf, David Brooks, Dehao Chen, Debojyoti Dutta, Udit Gupta, Kim Hazelwood, Andrew Hock, Xinyuan Huang, Bill Jia, Daniel Kang, David Kanter, Naveen Kumar, Jeffery Liao, <b>Deepak Narayanan</b>, Tayo Oguntebi, Gennady Pekhimenko, Lillian Pentecost, Vijay Janapa Reddi, Taylor Robie, Tom St. John, Carole-Jean Wu, Lingjie Xu, Cliff Young, Matei Zaharia. <br /><i>MLSys 2020.</i>
        <br>
        <br>
        <a href="assets/papers/pipedream-sosp19.pdf"><b>PipeDream: Generalized Pipeline Parallelism for DNN Training</b></a><br />
        <b>Deepak Narayanan</b>, Aaron Harlap, Amar Phanishayee, Vivek Seshadri, Nikhil R. Devanur, Gregory R. Ganger, Phillip B. Gibbons, Matei Zaharia. <br /><i>SOSP 2019.</i>
        <br>
        <br>
        <a href="assets/papers/dawnbench-sigops19.pdf"><b>Analysis of DAWNBench, a Time-to-Accuracy Machine Learning Performance Benchmark</b></a><br />
        Cody Coleman*, Daniel Kang*, <b>Deepak Narayanan*</b>, Luigi Nardi, Tian Zhao, Jian Zhang, Peter Bailis, Kunle Olukotun, Chris Ré, Matei Zaharia. <br /><i>SIGOPS Operating Systems Review July 2019.</i>
        <br>
        <br>
        <a href="assets/papers/modelbatch-neurips18.pdf"><b>Accelerating Deep Learning Workloads through Efficient Multi-Model Execution</b></a><br />
        <b>Deepak Narayanan</b>, Keshav Santhanam, Amar Phanishayee, Matei Zaharia. <br /><i>NeurIPS Systems for ML Workshop 2018.</i>
        <br>
        <br>
        <a href="assets/papers/dawnbench-neurips18.pdf"><b>Analysis of the Time-To-Accuracy Metric and Entries in the DAWNBench Deep Learning Benchmark</b></a><br />
        Cody Coleman*, Daniel Kang*, <b>Deepak Narayanan*</b>, Luigi Nardi, Tian Zhao, Jian Zhang, Peter Bailis, Kunle Olukotun, Chris Ré, Matei Zaharia. <br /><i>NeurIPS Systems for ML Workshop 2018.</i>
        <br>
        <br>
        <a href="assets/papers/weld-vldb18.pdf"><b>Evaluating End-to-End Optimization for Data Analytics Applications in Weld</b></a><br />
        Shoumik Palkar, James Thomas, <b>Deepak Narayanan</b>, Pratiksha Thaker, Parimarjan Negi, Rahul Palamuttam, Anil Shanbhag, Holger Pirk, Malte Schwarzkopf, Saman Amarasinghe, Samuel Madden, Matei Zaharia. <br /><i>VLDB 2018.</i>
        <br>
        <br>
        <a href="assets/papers/dawnbench-neurips17.pdf"><b>DAWNBench: An End-to-End Deep Learning Benchmark and Competition</b></a><br />
        Cody Coleman, <b>Deepak Narayanan</b>, Daniel Kang, Tian Zhao, Jian Zhang, Luigi Nardi, Peter Bailis, Kunle Olukotun, Christopher Re, Matei Zaharia. <br /><i>NeurIPS Systems for ML Workshop 2017.</i>
        <br>
        <br>
        <a href="assets/papers/macrobase-sigmod17.pdf"><b>MacroBase: Prioritizing Attention in Fast Data</b></a><br />
        Peter Bailis, Edward Gan, Samuel Madden, <b>Deepak Narayanan</b>, Kexin Rong, Sahaana Suri. <br /><i>SIGMOD 2017.</i>
        <br>
        <br>
        <a href="assets/papers/weld-cidr17.pdf"><b>Weld: A Common Runtime for High Performance Data Analytics</b></a><br />
        Shoumik Palkar, James J. Thomas, Anil Shanbhag, <b>Deepak Narayanan</b>, Holger Pirk, Malte Schwarzkopf, Saman Amarasinghe, Matei Zaharia. <br /><i>CIDR 2017.</i>
      </div>
    </div>

    <div id='publications'>
      <div class='heading'>Preprints</div>
      <div class='content'>
        <a href="assets/papers/thesis.pdf"><b>Resource-Efficient Execution of Deep Learning Computations</b></a><br />
        <b>Deepak Narayanan</b>. <br /><i>Ph.D. Thesis.</i>
        <br>
        <br>
        <a href="https://arxiv.org/pdf/2104.00282.pdf"><b>Allocation of Fungible Resources via a Fast, Scalable Price Discovery Method</b></a><br />
        Akshay Agrawal, Stephen Boyd, <b>Deepak Narayanan</b>, Fiodar Kazhamiaka, Matei Zaharia. <br /><i>arXiv:2104.00282.</i>
      </div>
    </div>

    <div id='teaching'>
      <div class='heading'>Teaching</div>
      <div class="content">
        At Stanford, I have TAed <a href=""><b>Design and Analysis of Algorithms</b></a> (CS 161), <a href="http://web.stanford.edu/class/cs245/spr2019/"><b>Principles of Data-Intensive Systems</b></a> (CS 245), and <a href="http://cs149.stanford.edu/fall19/"><b>Parallel Computing</b></a> (CS 149).
        <br>
        <br>
        At MIT, I TAed <a href="http://stellar.mit.edu/S/course/6/sp14/6.006/"><b>Introduction to Algorithms</b></a> (6.006), and
        <a href="http://stellar.mit.edu/S/course/6/sp15/6.046J/index.html"><b>Design and Analysis of Algorithms</b></a> (6.046). Before that, I was a Lab Assistant for <b>Elements of Software Construction</b> (6.005) and <b>Introduction to EECS I</b> (6.01).
      </div>
    </div>

    <div id='contact'>
      <div class='heading'>Contact me</div>
      <div class='content'>
        <a href="mailto: deepakn@cs.stanford.edu"><img src="assets/icons/gmail.svg" height="42" width="42"></a>
        <a href="http://github.com/deepakn94"><img src="assets/icons/github.svg" height="42" width="42"></a>
      </div>
    </div>

  </body>

</html>
